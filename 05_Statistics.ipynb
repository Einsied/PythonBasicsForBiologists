{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1370afe5-0e7f-477a-adf2-5ef6485295c5",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Statistics\n",
    "\n",
    "During the last few days, we learned fundamental programming.\n",
    "While this knowledge is useful, it usually needs to be paired with some basic knowledge about mathematics.\n",
    "Therefore, we will now investigate our signals a little bit deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f927b81-6166-4de7-abfb-b60e1d72b71e",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Inter spike interval](#Inter-spike-interval)\n",
    "2. [Simulation](#Simulation)\n",
    "3. [Compare model to reality](#Compare-model-to-reality)\n",
    "4. [Distributions](#Distributions)\n",
    "    1. [Normal distribution](#Normal-distribution)\n",
    "    2. [Mode](#Mode)\n",
    "    3. [Median](#Median)\n",
    "    4. [Gamma distribution](#Gamma-distribution)\n",
    "5. [Adapting our simulation code](#Adapting-our-simulation-code)\n",
    "6. [Fitting](#Fitting)\n",
    "7. [Numerical Integration](#Numerical-Integration)\n",
    "8. [Numerical differentiation](#Numerical-differentiation)\n",
    "9. [Rubber duck debugging](#Rubber-duck-debugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a567937-28d3-4738-acca-81b3e2e8cfaa",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Inter spike interval\n",
    "\n",
    "Between two spikes a neuro needs time to recover.\n",
    "This [refractory period](https://en.wikipedia.org/wiki/Refractory_period_(physiology)) has a minimal length.\n",
    "The units we showed you were filtered with multiple methods.\n",
    "One of them was the minimal refractory period.\n",
    "We will now investigate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2ad3a-5a62-4407-978c-bd19e0bdcd09",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simulation\n",
    "\n",
    "Considering that we have now \"incorrect unit\" we have to create one, but how?\n",
    "The answer to this is simulation.\n",
    "Especially in Physics simulations are often used tool to answer questions that cannot be answered with simple experiments.\n",
    "If we want to know how galaxies form we can neither make one in our own backyard nor can we observe it in our lifetimes,\n",
    "so we build a mathematical model in a computer and investigate it.\n",
    "\n",
    "In biology, computer simulations are more difficult to perform, because we lack a sufficiently advanced mathematical understanding of the problems we investigate.\n",
    "Expressed in a simpler way â€œit is easier to calculate how two galaxies collide, than how two cell interacts with each other.\n",
    "You can see this in the way we \"simulated\" the our two neurons.\n",
    "\n",
    "We take a starting point and then roll a random number afterwards.\n",
    "Adding the random number to the last time gives us the new spike time.\n",
    "Thereby we have a randomly firing neuron.\n",
    "\n",
    "We cover simulations, because I believe that during your career you will may encounter questions that can be answered by writing a short program and running it instead of using a plant or animal and that the use of simulation will slowly proliferate within biology.\n",
    "For the latter case always remember that a simulation is a simplified mathematical model and therefore flawed, so if you use it always ask which corners were cut and how this will influence your research.\n",
    "\n",
    "So if we now simulate a neurin our code could look like this:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "def create_random_neuron(start_time, minimal_delay, maximal_delay, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param minimal_delay the minimal distance between spikes (refractory period)\n",
    "    @param maximal_delay the maximal distance between spikes (no biologial meaning)\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = random.uniform(minimal_delay, maximal_delay)\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "# To ensure that the random module produces repeatable results we have to seed it\n",
    "# This makes sure if we run the same algortihm on two machines the results are equal\n",
    "# If you do not specify it a seed is chosen autoamtically, usually the system time\n",
    "random.seed(42)\n",
    "print(create_random_neuron(0, 0.2, 5.0, 100))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e71dd5-58e3-4b67-97ee-a60c0bccfe12",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Please use the code above to create a neuron.\n",
    "Then calculate the time difference between the spikes (inter-spike-interval) and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf90360-2b0d-45d8-b084-cc867985168d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code should be added here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d85f26-7be0-49bb-9d3f-a93931bdf5ec",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def create_random_neuron(start_time, minimal_delay, maximal_delay, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param minimal_delay the minimal distance between spikes (refractory period)\n",
    "    @param maximal_delay the maximal distance between spikes (no biologial meaning)\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = random.uniform(minimal_delay, maximal_delay)\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "# To ensure that the random module produces repeatable results we have to seed it\n",
    "# This makes sure if we run the same algortihm on two machines the results are equal\n",
    "# If you do not specify it a seed is chosen autoamtically, usually the system time\n",
    "random.seed(42)\n",
    "random_spikes = create_random_neuron(0, 0.2, 5.0, 100)\n",
    "interval_random_spikes = get_inter_spike_intervals(random_spikes)\n",
    "\n",
    "matplotlib.pyplot.hist(interval_random_spikes)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e7589-c64d-48e6-b4c9-155579181452",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Compare model to reality\n",
    "\n",
    "You have seen a rough distribution, but to correctly fine tune your model you should compare it to reality.\n",
    "Please read in the contents of ```./data_neuron/session_2023111501010_units.csv``` as we did last time and plot the inter-spike-interval of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e156c69-8869-43db-a50d-301466aecb44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code should be added here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26685b-0dbd-4d61-b4e8-bd43e16e5f01",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def create_random_neuron(start_time, minimal_delay, maximal_delay, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param minimal_delay the minimal distance between spikes (refractory period)\n",
    "    @param maximal_delay the maximal distance between spikes (no biologial meaning)\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = random.uniform(minimal_delay, maximal_delay)\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "spikes_times_units = get_spike_times_for_all_units(units_file_path)\n",
    "max_duration = 0\n",
    "for unit_id in spikes_times_units.keys():\n",
    "    max_time_unit = max(spikes_times_units[unit_id])\n",
    "    max_duration = max(max_time_unit, max_duration)\n",
    "\n",
    "for unit in spikes_times_units.keys():\n",
    "    matplotlib.pyplot.title(f\"Unit {unit}\")   \n",
    "    matplotlib.pyplot\n",
    "    matplotlib.pyplot.hist(get_inter_spike_intervals(spikes_times_units[unit]))\n",
    "    matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "    matplotlib.pyplot.ylabel(\"Number of spikes\")\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "random.seed(42)\n",
    "random_spikes = create_random_neuron(0, 0.2, 5.0, max_duration)\n",
    "interval_random_spikes = get_inter_spike_intervals(random_spikes)\n",
    "\n",
    "matplotlib.pyplot.title(f\"Simulation\")\n",
    "matplotlib.pyplot.hist(interval_random_spikes)\n",
    "matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "matplotlib.pyplot.ylabel(\"Number of spikes\")\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cff17a-2696-44b2-b950-da7fedae42a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def create_random_neuron(start_time, minimal_delay, maximal_delay, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param minimal_delay the minimal distance between spikes (refractory period)\n",
    "    @param maximal_delay the maximal distance between spikes (no biologial meaning)\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = random.uniform(minimal_delay, maximal_delay)\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "spikes_times_units = get_spike_times_for_all_units(units_file_path)\n",
    "max_duration = 0\n",
    "for unit_id in spikes_times_units.keys():\n",
    "    max_time_unit = max(spikes_times_units[unit_id])\n",
    "    max_duration = max(max_time_unit, max_duration)\n",
    "\n",
    "for unit in spikes_times_units.keys():\n",
    "    matplotlib.pyplot.title(f\"Unit {unit}\")   \n",
    "    matplotlib.pyplot\n",
    "    matplotlib.pyplot.hist(get_inter_spike_intervals(spikes_times_units[unit]))\n",
    "    matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "    matplotlib.pyplot.ylabel(\"Number of spikes\")\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "random.seed(42)\n",
    "random_spikes = create_random_neuron(0, 0.2, 5.0, max_duration)\n",
    "interval_random_spikes = get_inter_spike_intervals(random_spikes)\n",
    "\n",
    "matplotlib.pyplot.title(f\"Simulation\")\n",
    "matplotlib.pyplot.hist(interval_random_spikes)\n",
    "matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "matplotlib.pyplot.ylabel(\"Number of spikes\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e539c50-1eea-45e1-ae62-095d51907a07",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Distributions\n",
    "\n",
    "As you have observed our simulated neuron does not look like any of the units we measured at all.\n",
    "To answer the question why we have to do a little bit more statisic.\n",
    "In our simulation we used ```random.uniform```, this means all numbers between lower and upper bound had the same chance to be drawn,\n",
    "so our interrvals were equally distributed.\n",
    "\n",
    "The real data show a bias towards lower numbers however.\n",
    "So they are not equally distributed.\n",
    "This means we need to look at different distributions, so we can correctly simulate a neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001413d-96a3-4b22-94b5-540854527029",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Normal distribution\n",
    "\n",
    "The most often used distribution is the [normal or gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution).\n",
    "It is biased towards a center point which is also its average or [mean](https://en.wikipedia.org/wiki/Mean#Mean_of_a_probability_distribution).\n",
    "It spreads around its mean, ths size of the spread is described by the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation).\n",
    "The standard deviation can be used how probable values are.\n",
    "The further away the less likely we are to draw the value.\n",
    "The chance to draw from an interval and the corresponding standard deviation ($\\sigma$) is visualized in the following figure from\n",
    "[Wikipedia](https://commons.wikimedia.org/wiki/File:Standard_deviation_diagram.svg):\n",
    "\n",
    "![A bell shaped normal distribution](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/640px-Standard_deviation_diagram.svg.png)\n",
    "\n",
    "If we add up the numbers we find out that 68.2 % of all values are within $1 \\sigma $ of the mean.\n",
    "\n",
    "Now why do we care?\n",
    "The answer is the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem).\n",
    "Simplified it states: \"If you combine a large number of independent random variables, the resulting distribution will be the normal distribution.\"\n",
    "Since a lot of things are independent random variables this distribution is very common.\n",
    "So if you throw a dice often enough the sum of the eyes is a normally distributed,\n",
    "if you measure the blood pressure of people you expect it to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc2d7c-7c7d-4953-b581-9f42ae3241b1",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To get acquainted with the normal distribution please create one with ```random.gauss``` and use ```numpy.mean``` and ```numpy.std``` to recover the mean and standard deviation values you set.\n",
    "Please interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40175d88-9f51-4ffc-ba87-61b35f1bb596",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbc548-d5b6-4fcf-8e4a-6eacaba25910",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "# Higher sample numbers lead to a better approximation\n",
    "number_of_samples = 10000\n",
    "# Chose an arbitrary number here\n",
    "random.seed(12)\n",
    "\n",
    "# The standard deviation has to be bigger than 0\n",
    "# otherwise you can chose any number you want\n",
    "mean = 2.5\n",
    "standard_deviation = 3.0\n",
    "\n",
    "values = list()\n",
    "for index in range(0, number_of_samples):\n",
    "    values.append(random.gauss(mean, standard_deviation))\n",
    "\n",
    "print(f\"Mean given: {mean}, calculated: {numpy.mean(values)}\")\n",
    "print(f\"Standard deviation given:{standard_deviation}, calculated {numpy.std(values)}\")\n",
    "```\n",
    "\n",
    "Running the code we fail to recover mean and standard deviation.\n",
    "This lies in the nature of random variables,\n",
    "they approach the values of the distribution with higher sample numbers,\n",
    "but will only reproduce them if the sample size reaches infinity.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494cd0e-e07a-444e-80b4-18ed416167e6",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Mode\n",
    "\n",
    "If we compare the normal distribution to the data we obtained we may find it an unsatisfying approximation.\n",
    "Something does not fit, most of the values should shift to the left,\n",
    "in other words the [mode](https://en.wikipedia.org/wiki/Mode_(statistics)) is wrong.\n",
    "\n",
    "The mode is the most common value within a distribution, in other words its \"peak\".\n",
    "So we need to search for a distribution in which the mode differs from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17858e29-f8c3-4c1d-a029-02366b4ddd6f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Median\n",
    "\n",
    "Before we talk about this better distribution lets us talk about another useful statistical measure:\n",
    "the [median](https://en.wikipedia.org/wiki/Median) or the value in the middle.\n",
    "\n",
    "We often use it to overcome the sensibility of the mean to outliers.\n",
    "Let me give you a simple example based on a list of buckets:\n",
    "\n",
    "| Bucket | Content |\n",
    "| ------ | ------- |\n",
    "| 1      | 0.4     |\n",
    "| 2      | 0.5     |\n",
    "| 3      | 0.6     |\n",
    "| 4      | 0.5     |\n",
    "| 5      | 8.0     |\n",
    "\n",
    "If you ask how much content do I get if I combine them the average of 1.0 l might be helpful,\n",
    "but if you get one at random and ask how much content should you expect the median of 0.5 l might be the better measurement.\n",
    "It is often more useful for very assymetric distributions like [wealth](https://en.wikipedia.org/wiki/Economic_inequality),\n",
    "as shown in the following figure from [wikipedia](https://en.wikipedia.org/wiki/File:Global_Wealth_Distribution_2020_(Property).svg).\n",
    "\n",
    "![A figure showing that a small fraction of the worlds population owns most of the world material wealth](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Global_Wealth_Distribution_2020_%28Property%29.svg/444px-Global_Wealth_Distribution_2020_%28Property%29.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e40a0-0325-48bd-bb66-d0ff43fa776e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Gamma distribution\n",
    "\n",
    "Now thatwe have learned more about statistics let us search for a distribution,\n",
    "that is similar to the normal distribution but has a shifted mode.\n",
    "The first choice would be the [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution),\n",
    "which is the continious equivalent to the [poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution).\n",
    "To better visualize it lets look at this figure from [wikipedia](https://en.wikipedia.org/wiki/File:Gammapdf252.svg).\n",
    "\n",
    "![Multiple examples of the gamma distribution](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Gammapdf252.svg/384px-Gammapdf252.svg.png)\n",
    "\n",
    "As you can see we have a parameter $\\alpha$ influencing the position of the mode within all values\n",
    "and a parameter $\\beta$ influencing the spread of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419916a9-97a0-4eb1-b091-ca5008e3f28e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can draw from this distribution using ```random.gammavariate```.\n",
    "Please draw a few samples and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea4aa3-ba84-4776-9dea-50d89c30104c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efcf90-d188-43b2-9dca-eedbcafff6eb",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "\n",
    "# Higher sample numbers lead to a better approximation\n",
    "number_of_samples = 10000\n",
    "# Chose an arbitrary number here\n",
    "random.seed(15)\n",
    "\n",
    "# The standard deviation has to be bigger than 0\n",
    "# otherwise you can chose any number you want\n",
    "shape = 3\n",
    "width = 5\n",
    "\n",
    "values = list()\n",
    "for index in range(0, number_of_samples):\n",
    "    values.append(random.gammavariate(shape, scale))\n",
    "\n",
    "matplotlib.pyplot.hist(values)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0409a-efe6-4558-905b-0bcb8425dad9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Adapting our simulation code\n",
    "\n",
    "Now that we have found a fitting function to describe our neurons,\n",
    "we can try to add it into code.\n",
    "Instead of drawing from a uniform distribution we now want to draw from an arbitrary distribution,\n",
    "so we give  ```def create_random_neuron``` a **function** as an argument.\n",
    "From this **function** we then get a distance,\n",
    "so our code would look like this:\n",
    "\n",
    "```Python\n",
    "def create_random_neuron(start_time, get_distance, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param get_distance a function returning a distance\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = get_distance()\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "```\n",
    "\n",
    "We would then supply the **function** by creating a wrapper filling in the arguments:\n",
    "\n",
    "```Python\n",
    "# Example values\n",
    "shape = 2.0\n",
    "width = 3.0\n",
    "\n",
    "def get_distance():\n",
    "    return random.gammavariant(shape, width)\n",
    "\n",
    "create_random_neuron(0, get_distance, 40)\n",
    "```\n",
    "\n",
    "This is a little bit inconvenient, because we would have to create one global **variable** for every **function** we generate,\n",
    "so we have to find a more elegant solution.\n",
    "So we write a **function** generating a **function** with these paremeters:\n",
    "\n",
    "```Python\n",
    "def get_gamma(shape, width):\n",
    "    def sample_gamma():\n",
    "        return random.gammavariant(shape, width)\n",
    "    return sample_gamma\n",
    "\n",
    "create_random_neuron(0, get_gamma(2.0, 3.0), 40)\n",
    "```\n",
    "\n",
    "There is of coures a way to write this shorter using [lambda expressions](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions).\n",
    "Lambda expressions are short nameless functions.\n",
    "The begin with the keyword ```lambda``` followed by the list of arguments and a ```:```.\n",
    "After the ```:``` the return value follows.\n",
    "Here is a short example:\n",
    "\n",
    "```Python\n",
    "def square_(x)\n",
    "    return x**2\n",
    "a = square\n",
    "\n",
    "# Now the same as a lambda expression\n",
    "a = lablda x: x**2\n",
    "````\n",
    "\n",
    "Using lambda expressions our code would the look like this:\n",
    "\n",
    "```Python\n",
    "create_random_neuron(0, lambda : random.gammavariant(shape, width), 40)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ea00a-c55c-4bb6-9517-3db94954f2ca",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To get acquainted with **functions** as arguments please simulate a neuron once with a gaussian and then a gamma distribution.\n",
    "Use lambda expressions for one of them.\n",
    "Please visualize the inter-spike-invervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d995582-f471-4ded-bdef-48cf36b0e6ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661ee36-ba5a-47e2-bd30-01d656488ecf",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def create_random_neuron(start_time, get_distance, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param get_distance a function returning a distance\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    last_time = start_time\n",
    "    while True:\n",
    "        time_difference = get_distance()\n",
    "        # Since both our distirbutions can generate negative values,\n",
    "        # we should redraw until we get positive ones\n",
    "        while time_difference <= 0:\n",
    "            time_difference = get_distance()\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "def get_gaussian(mean, std):\n",
    "    def sample_gaussian():\n",
    "        return random.gauss(mean, std)\n",
    "    return sample_gaussian\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Finding good parameters here may take a while\n",
    "gauss_values = create_random_neuron(0, get_gaussian(0.7, 0.2), 500)\n",
    "gamma_values = create_random_neuron(0, lambda: random.gauss(0.3, 0.7), 500)\n",
    "\n",
    "matplotlib.pyplot.title(\"Gauss\")\n",
    "matplotlib.pyplot.hist(get_inter_spike_intervals(gauss_values))\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "matplotlib.pyplot.title(\"Gamma\")\n",
    "matplotlib.pyplot.hist(get_inter_spike_intervals(gamma_values))\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb4742-0b1b-41ee-a0ff-b8599e1c0c09",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fitting\n",
    "\n",
    "Now that we have found a fitting function to describe our unit,\n",
    "we stil lack the correct parameter.\n",
    "What are ```shape``` and ```width``` for our units?\n",
    "\n",
    "To answer this we can fit a function to our data.\n",
    "Fitting in itself is not a easy topic, especially if we have higher dimensional data.\n",
    "Instead of doing a side lecture we will use ```scipy.optimize.curve_fit``` and hope for the best.\n",
    "As an example we will fit a gaussian to our dat.\n",
    "\n",
    "Since this is not the easiest function we will use it as an exmaple an exercise on a polynomial later.\n",
    "\n",
    "To fit a function we first have to create it.\n",
    "```scipy.optimize.curve_fit```, will replace the first value in it and optimize the rest.\n",
    "So we write the function as a Python **function**:\n",
    "\n",
    "```Python\n",
    "def gauss(x, mean, std, scale):\n",
    "    divisor = numpy.sqrt(2 * numpy.pi * (std**2))\n",
    "    exponent = -((x - mean)**2) / (2 * (std**2)) \n",
    "    return numpy.exp(exponent) /  divisor\n",
    "```\n",
    "\n",
    "We then get the values to fit.\n",
    "We need x-values and corresponding y-values for the curve fit.\n",
    "We will obtain those by using ```numpy.histogram```.\n",
    "Considering that the normal distribution is a probability distirbution we have to normalize the bins-sizes by the total sample size:\n",
    "\n",
    "```\n",
    "y_values = bin_values / len(inter_spike_intervals)\n",
    "```\n",
    "\n",
    "Finally will call curve fit and investigate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb74a78-3593-4116-a0d6-6a82b591b085",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Please execute the cell below and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080c94a-4166-41cc-9347-c44267af6ab9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import pathlib\n",
    "import csv\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def gauss(x, mean, std):\n",
    "    divisor = numpy.sqrt(2 * numpy.pi * (std**2))\n",
    "    exponent = -((x - mean)**2) / (2 * (std**2)) \n",
    "    return numpy.exp(exponent) /  divisor\n",
    "    \n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "# We chose unit 17 here because it is rather broad\n",
    "inter_spike_intervals = get_inter_spike_intervals(get_spike_times_for_all_units(units_file_path)[17])\n",
    "\n",
    "bin_values, bin_edges = numpy.histogram(inter_spike_intervals, bins = 500)\n",
    "y_values = bin_values / len(inter_spike_intervals)\n",
    "# Average the bin edges into bin values\n",
    "x_values = bin_edges[:-1] + bin_edges[1] / 2\n",
    "\n",
    "parameters, covariance = scipy.optimize.curve_fit(gauss, x_values, y_values)\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, gauss(x_values, *parameters))\n",
    "matplotlib.pyplot.plot(x_values, y_values)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5661251-5557-4dfb-893b-9c329656a700",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The gamma-distribution is given in the following form according to its [documentation](https://docs.python.org/3/library/random.html#real-valued-distributions):\n",
    "$$       \n",
    "\\gamma(x) =  \\frac{x ^{\\alpha - 1}  e^{-x / \\beta}}{\\Gamma(alpha)  \\beta^{\\alpha}}\n",
    "$$\n",
    "\n",
    "This can not be fitted directly, instead we will have to use a specialized function for it.\n",
    "If you encounter functions that are difficutl to describe or can not easily fit,\n",
    "consider fitting a [polynomial](https://en.wikipedia.org/wiki/Polynomial).\n",
    "They often yield good enoug results.\n",
    "Pleas use the cell below to fit a polynomial of 5 degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d153d-82e5-45dc-a76c-be188cc72f9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25e1cd-a5c3-4740-9b74-dbbf078020aa",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import numpy\n",
    "import scipy\n",
    "import pathlib\n",
    "import csv\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def polynomial(x, a0, a1, a2, a3, a4, a5):\n",
    "    return a0 + x*a1 + x**2*a2 + x**3*a3 + x**4*a4 + x**5*a5\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "# We chose unit 17 here because it is rather broad\n",
    "inter_spike_intervals = get_inter_spike_intervals(get_spike_times_for_all_units(units_file_path)[17])\n",
    "\n",
    "bin_values, bin_edges = numpy.histogram(inter_spike_intervals, bins = 500)\n",
    "y_values = bin_values / len(inter_spike_intervals)\n",
    "# Average the bin edges into bin values\n",
    "x_values = bin_edges[:-1] + bin_edges[1] / 2\n",
    "\n",
    "parameters, covariance = scipy.optimize.curve_fit(polynomial, x_values, y_values)\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, polynomial(x_values, *parameters))\n",
    "matplotlib.pyplot.plot(x_values, y_values)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5c4d4-cd5f-410f-acd2-23ffa73a21fa",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As mentioned previously the polynomial does not fit our distribution well,\n",
    "so we have will now fit the distirbution directly.\n",
    "Pleas consult the [documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html) of ```scipy.stats.gamma```\n",
    "especially the fit **method** and use it to fit our data.\n",
    "Then display the probability density function (pdf).\n",
    "Forcefully normalize it to one, so it can be compared to our data:\n",
    "```fit_y_values /= numpy.sum(fit_y_values)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d49f9c-4b90-4d34-9c34-d65538c7c1ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6051d-238c-459f-b05d-0e8aaa40604b",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import scipy\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "inter_spike_intervals_unit = get_inter_spike_intervals(get_spike_times_for_all_units(units_file_path)[17])\n",
    "\n",
    "values, bin_edges = numpy.histogram(inter_spike_intervals_unit, bins = 500)\n",
    "y_values = values / len(inter_spike_intervals_unit)\n",
    "# Average the bin edges into bin values\n",
    "x_values = bin_edges[:-1] + bin_edges[1] / 2\n",
    "\n",
    "fitted_values = scipy.stats.gamma.fit(inter_spike_intervals_unit)\n",
    "\n",
    "# Scipy produces a none normalize probabilty density function, which we have to correct\n",
    "fit_y_values = scipy.stats.gamma.pdf(x_values, *fitted_values)\n",
    "fit_y_values /= numpy.sum(fit_y_values)\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, fit_y_values)\n",
    "matplotlib.pyplot.plot(x_values, y_values)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f8b9b-38dd-4efb-ae69-ae65ff987ea2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Numerical Integration\n",
    "\n",
    "As you see our plots are quite similar, but why did we have to normalize?\n",
    "The answer is that the pdf is the probability-*density*-function, so it describes the density of the probability.\n",
    "To get the real probability we have to integrate it.\n",
    "\n",
    "Since we have a computer at our hands we will integrate it [numericaly](https://en.wikipedia.org/wiki/Numerical_integration).\n",
    "You may recall from yourn studies that an [integral](https://en.wikipedia.org/wiki/Integral) is the continious analogue to a sum,\n",
    "so numerical integration just means we sum things up.\n",
    "\n",
    "We will use the [quadrature rule based on step functions](https://en.wikipedia.org/wiki/Numerical_integration#Quadrature_rules_based_on_step_functions).\n",
    "This means we will integrate at a point by forming a rectangle around it.\n",
    "The width of the rectangle is defined by our step-size, which we have to choose corrctly.\n",
    "The height is the center value of the step.\n",
    "We can either obtain it by broadening one value or averaging between two values.\n",
    "Here is an illsutration from [wikipedia](https://commons.wikimedia.org/wiki/File:Integration_rectangle.svg) demonstrating this integration:\n",
    "\n",
    "![A graph showing boxes on a curve](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Integration_rectangle.svg/640px-Integration_rectangle.svg.png)\n",
    "\n",
    "Here is a short example integrating a polynomial with both methods:\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def poylnomial(x):\n",
    "    return x**2\n",
    "\n",
    "def integrate_one_value(begin, end, function, step_size):\n",
    "    y_values = list()\n",
    "    current_value = 0\n",
    "    for x_value in range(begin, end + 1, step_size):\n",
    "        current_value += function(x_value) * step_size\n",
    "        y_values.append(current_value)\n",
    "    return y_values\n",
    "\n",
    "def integrate_average(begin, end, function, step_size):\n",
    "    y_values = list()\n",
    "    current_value = 0\n",
    "    for x_value in range(begin, end + 1, step_size):\n",
    "        half_step = step_size / 2\n",
    "        average_height = (function(x_value - half_step) + function(x_value + half_step)) / 2\n",
    "        current_value += average_height  * step_size\n",
    "        y_values.append(current_value)\n",
    "    return y_values\n",
    "\n",
    "begin = 0\n",
    "end = 100\n",
    "step_size = 1\n",
    "x_values = range(begin, end + 1, step_size)\n",
    "\n",
    "y_values_one = integrate_one_value(begin, end, poylnomial, step_size)\n",
    "y_values_average = integrate_average(begin, end, poylnomial, step_size)\n",
    "y_values_analytic = [x**3/3 for x in x_values]\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, y_values_one, label = \"One value\")\n",
    "matplotlib.pyplot.plot(x_values, y_values_average, label = \"Average\")\n",
    "matplotlib.pyplot.plot(x_values, y_values_analytic, label = \"Analytic\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc6273-0148-4fca-8f29-0ac030a2d84f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Please use the knowledge you gained to integrate the cosinus.\n",
    "To get better results you may wish to use ```numyp.arange``` and use smaller step_sizes.\n",
    "Liming the end of the integration to a low multiple of $\\pi$ using ```numpy.pi``` might also be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd859931-cb8e-47e7-af92-914218eee464",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fb2ce-68a0-4bbe-9094-9aeebb7bcb4b",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "\n",
    "def integrate_one_value(begin, end, function, step_size):\n",
    "    y_values = list()\n",
    "    current_value = 0\n",
    "    for x_value in numpy.arange(begin, end + 1, step_size):\n",
    "        current_value += function(x_value) * step_size\n",
    "        y_values.append(current_value)\n",
    "    return y_values\n",
    "\n",
    "def integrate_average(begin, end, function, step_size):\n",
    "    y_values = list()\n",
    "    current_value = 0\n",
    "    for x_value in numpy.arange(begin, end + 1, step_size):\n",
    "        half_step = step_size / 2\n",
    "        average_height = (function(x_value - half_step) + function(x_value + half_step)) / 2\n",
    "        current_value += average_height  * step_size\n",
    "        y_values.append(current_value)\n",
    "    return y_values\n",
    "\n",
    "begin = 0\n",
    "end = 8*numpy.pi\n",
    "step_size = end/300\n",
    "x_values = numpy.arange(begin, end + 1, step_size)\n",
    "\n",
    "y_values_one = integrate_one_value(begin, end, numpy.cos, step_size)\n",
    "y_values_average = integrate_average(begin, end, numpy.cos, step_size)\n",
    "y_values_analytic = [numpy.sin(x) for x in x_values]\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, y_values_one, label = \"One value\")\n",
    "matplotlib.pyplot.plot(x_values, y_values_average, label = \"Average\")\n",
    "matplotlib.pyplot.plot(x_values, y_values_analytic, label = \"Analytic\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f7cf6-9321-4bb6-a841-fc9d54235137",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can now finally finish testing our fit.\n",
    "Using the one value method we mutliply all the y-values of the pdf with a step-size and obtain the probability belonging to every x-value.\n",
    "The step size is given as the distance between the x-values, because we need to sample the distribtuion fully.\n",
    "Below you find the final code to investigate our fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5eeea-c614-4bb3-9db9-c99e223a2d9e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import scipy\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "inter_spike_intervals_unit = get_inter_spike_intervals(get_spike_times_for_all_units(units_file_path)[17])\n",
    "\n",
    "values, bin_edges = numpy.histogram(inter_spike_intervals_unit, bins = 500)\n",
    "y_values = values / len(inter_spike_intervals_unit)\n",
    "# Average the bin edges into bin values\n",
    "x_values = (bin_edges[:-1] + bin_edges[1]) / 2\n",
    "\n",
    "fitted_values = scipy.stats.gamma.fit(inter_spike_intervals_unit)\n",
    "\n",
    "# Scipy produces a none normalize probabilty density function, which we have to correct through integration\n",
    "# Using the step_distance we can turn our density into a probability\n",
    "step_distance = x_values[1] - x_values[0]\n",
    "fit_y_values = scipy.stats.gamma.pdf(x_values, *fitted_values) * step_distance\n",
    "\n",
    "matplotlib.pyplot.plot(x_values, fit_y_values, label= \"Fit\")\n",
    "matplotlib.pyplot.plot(x_values, y_values, label = \"Data\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3c80d-f5d8-4e35-be7e-39c9df73eb0f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We now have the parameters to finish our simulation and finish our neuron.\n",
    "We can now use ```scipy.stats.gamma.rvs``` with the fit parameters to simulate the neuron an plot it\n",
    "as shown in the cell below.\n",
    "Please execute it and enjoy the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e6777-d2ef-4b88-b80f-9c9ea731f192",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "import csv\n",
    "import numpy\n",
    "import scipy\n",
    "\n",
    "def create_random_neuron(start_time, get_distance, end_recording):\n",
    "    \"\"\"!\n",
    "    @brief Creates random neuron data\n",
    "    @details This creates a uniformly disributed neuron signal\n",
    "\n",
    "    @param start_time the beginning of the firing\n",
    "    @param get_distance a function returning a distance\n",
    "    @param end_recording the largest permitted spike time\n",
    "    @return a list with spike times\n",
    "    \"\"\"\n",
    "    spike_times = list()\n",
    "    # Note that the start time is not a spike otherwise the results would not be random enough\n",
    "    last_time = start_time\n",
    "    while True: # This is Pythons version of a do while loop: https://en.wikipedia.org/wiki/Do_while_loop\n",
    "        time_difference = get_distance()\n",
    "        last_time += time_difference\n",
    "        if last_time < end_recording:\n",
    "            spike_times.append(last_time)\n",
    "        else:\n",
    "            break\n",
    "    return spike_times\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "    return differences\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "inter_spike_intervals_unit = get_inter_spike_intervals(get_spike_times_for_all_units(units_file_path)[17])\n",
    "\n",
    "values, bin_edges = numpy.histogram(inter_spike_intervals_unit, bins = 500)\n",
    "y_values = values / len(inter_spike_intervals_unit)\n",
    "# Average the bin edges into bin values\n",
    "x_values = (bin_edges[:-1] + bin_edges[1]) / 2\n",
    "\n",
    "fitted_values = scipy.stats.gamma.fit(inter_spike_intervals_unit)\n",
    "\n",
    "# Scipy produces a none normalize probabilty density function, which we have to correct\n",
    "step_distance = x_values[1] - x_values[0]\n",
    "fit_y_values = scipy.stats.gamma.pdf(x_values, *fitted_values) * step_distance\n",
    "\n",
    "# Scipy uses numpy random instead of random, so we have to seed it instead\n",
    "numpy.random.seed(42)\n",
    "random_spikes = create_random_neuron(0, lambda:scipy.stats.gamma.rvs(*fitted_values), 3400)\n",
    "interval_random_spikes = get_inter_spike_intervals(random_spikes)\n",
    "\n",
    "matplotlib.pyplot.title(f\"Simulation\")\n",
    "matplotlib.pyplot.hist(interval_random_spikes)\n",
    "matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "matplotlib.pyplot.ylabel(\"Number of spikes\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959cb46-58e0-4b0d-86d7-9df80316fea1",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Numerical differentiation\n",
    "\n",
    "Now that we have succesfully simulated and integrated there is one topic left:\n",
    "[numerical differentiation](https://en.wikipedia.org/wiki/Numerical_differentiation).\n",
    "It is the counter part to numerical integration and we can use it to get a derivative.\n",
    "\n",
    "During my high-school time the derivative was introduced via the [slope](https://en.wikipedia.org/wiki/Slope) of a function.\n",
    "We counted how much we went up or down on one axis comparted to the other,\n",
    "as shown in the following [illustration from Wikipedia](https://commons.wikimedia.org/wiki/File:Wiki_slope_in_2d.svg):\n",
    "\n",
    "![A slope illustrated with the interval steps on the x- and y-axis](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Wiki_slope_in_2d.svg/445px-Wiki_slope_in_2d.svg.png)\n",
    "\n",
    "Luckily, for us [numerical differentiation](https://en.wikipedia.org/wiki/Numerical_differentiation) did not progress much further, so we get the first derivative with the the original formula:\n",
    "\n",
    "$$\n",
    "m = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}}\n",
    "$$\n",
    "\n",
    "This gives us the forward slope, an approximation for the first order derivative.\n",
    "We can now abstract the formula by introducing the stepsize $h$.\n",
    "Our formula now takes the following form:\n",
    "\n",
    "$$\n",
    "f^{'}(x) = \\frac{f(x + h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "If you need a symmetric derivative, you may choose to look around the point of interest and use:\n",
    "\n",
    "$$\n",
    "f^{'}(x) = \\frac{f(x + h) - f(x - h)}{2 h}\n",
    "$$\n",
    "\n",
    "Should you need to calculate derivatives of mathematical functions you should look up [Taylor expansion](https://en.wikipedia.org/wiki/Taylor_series) and [finite difference coefficients](https://en.wikipedia.org/wiki/Finite_difference_coefficient).\n",
    "In this case you should also pay attention to the size of h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4c2ec-155f-45d8-ac0b-1a8e2d3e74dd",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As a first exercise please calculate and visualize the numerical derivative of $x^{3}$ betwen 0 and 10 in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86823a01-8583-49b9-9a04-539a9d5f25ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f19d57-120a-461c-8057-65624598a355",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "\n",
    "def get_forward_derivative(series_x, series_y):\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(0, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index]\n",
    "        delta_y = series_y[index + 1] - series_y[index]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "\n",
    "def get_symmetric_derivative(series_x, series_y):\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(1, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index - 1]\n",
    "        delta_y = series_y[index + 1] - series_y[index - 1]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "\n",
    "function = lambda x: x**3\n",
    "analytic_derivative = lambda x: 3*(x**2)\n",
    "step_size = 0.1\n",
    "lower_bound = 0\n",
    "upper_bound = 10\n",
    "x_values = numpy.arange(lower_bound, upper_bound + step_size, step_size)\n",
    "y_values = [function(x) for x in x_values]\n",
    "y_values_analytic_derivative = [analytic_derivative(x) for x in x_values]\n",
    "x_values_forward, y_values_forward = get_forward_derivative(x_values, y_values)\n",
    "x_values_symmetric, y_values_symmetric = get_symmetric_derivative(x_values, y_values)\n",
    "\n",
    "# Plot the analytic derivative to see if we are correct\n",
    "matplotlib.pyplot.plot(x_values, y_values_analytic_derivative, label=\"$3 x^{2}$\")\n",
    "matplotlib.pyplot.plot(x_values_forward, y_values_forward, label=\"Forward\")\n",
    "matplotlib.pyplot.plot(x_values_symmetric, y_values_symmetric, label=\"Symmetric\")\n",
    "\n",
    "matplotlib.pyplot.title(f\"Derivatives\")\n",
    "matplotlib.pyplot.xlabel(\"x\")\n",
    "matplotlib.pyplot.ylabel(\"y\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29d734-c085-4344-bbdf-d832b4bd6ec8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To round up this topic I would ask you to calculate the derivatives of the inter-spike-interval.\n",
    "As the step-size $h$ use the index itself, by iterating over the recorded values.\n",
    "Please, visualize them and their time dependence using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f90e4-4d4c-41cc-aea4-43f2226b1acd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# Feel free to copy from above what you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01958c-d1cd-4aad-a8d3-8dbac0b093e6",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import random\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def get_forward_derivative(series_x, series_y):\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(0, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index]\n",
    "        delta_y = series_y[index + 1] - series_y[index]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "\n",
    "def get_symmetric_derivative(series_x, series_y):\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(1, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index - 1]\n",
    "        delta_y = series_y[index + 1] - series_y[index - 1]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "\n",
    "def get_spike_times_for_all_units(units_file_path):\n",
    "    unit_spike_times = dict()\n",
    "    with open(units_file_path, \"r\") as units_file:\n",
    "        reader = csv.DictReader(units_file)\n",
    "        for row in reader:\n",
    "            unit_id = int(row[\"unitID\"])\n",
    "            if unit_id not in unit_spike_times.keys():\n",
    "                unit_spike_times[unit_id] = list()\n",
    "            spike_time = float(row[\"spikeTimes\"])\n",
    "            unit_spike_times[unit_id].append(spike_time)\n",
    "    return unit_spike_times\n",
    "\n",
    "def get_inter_spike_intervals(spike_times):\n",
    "    differences = list()\n",
    "    times = list()\n",
    "    for index in range(0, len(spike_times) - 1):\n",
    "        difference = spike_times[index + 1] - spike_times[index]\n",
    "        differences.append(difference)\n",
    "        average_time = (spike_times[index + 1] + spike_times[index]) / 2\n",
    "        times.append(average_time)\n",
    "    return differences, times\n",
    "\n",
    "data_path = pathlib.Path(\"./data_neuron/\")\n",
    "units_file_path = data_path / \"session_2023111501010_units.csv\"\n",
    "\n",
    "spikes_times_units = get_spike_times_for_all_units(units_file_path)\n",
    "max_duration = 0\n",
    "for unit_id in spikes_times_units.keys():\n",
    "    max_time_unit = max(spikes_times_units[unit_id])\n",
    "    max_duration = max(max_time_unit, max_duration)\n",
    "\n",
    "for unit in spikes_times_units.keys():\n",
    "    differences, times = get_inter_spike_intervals(spikes_times_units[unit])\n",
    "    times, derivative = get_symmetric_derivative(times, differences)\n",
    "    matplotlib.pyplot.plot(times, derivative, label=f\"Unit {unit}\")\n",
    "matplotlib.pyplot.title(\"Derivatives\")\n",
    "matplotlib.pyplot.xlabel(\"Interval in seconds\")\n",
    "matplotlib.pyplot.ylabel(\"Change in interval length\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eab2e-0c30-4b86-89b9-384d606375f0",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Rubber duck debugging\n",
    "\n",
    "During this course, you were able to work with your partners.\n",
    "Working on the course together, you were able to engage naturally in [pair programming](https://en.wikipedia.org/wiki/Pair_programming) and [code review](https://en.wikipedia.org/wiki/Code_review). \n",
    "These methods greatly improve your understanding of the problem and thereby your code.\n",
    "It is unfortunately difficult to communicate the advantages of efficient work to superior and colleagues.\n",
    "The preferred standard is to let two people on two desks solve in eight days, what two people on one desk could have solved in four.\n",
    "Therefore, you will find yourself most probably working on your problems alone.\n",
    "Luckily, not some of the benefits of working with a partner can be gained without one.\n",
    "\n",
    "A good example of this is [rubber duck debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging).\n",
    "It is especially useful for novice programmers as yourself or problems with many steps.\n",
    "The general idea is that explaining something requires you to think more deeply about it,\n",
    "therefore you can improve your understanding and by explaining.\n",
    "So, you need to explain your code to figure out why it does not do what it is supposed to.\n",
    "While a live human can contribute his or her own insights, a rubber duck is sufficient to gain your own.\n",
    "So if you struggle with a problem take a rubber duck and explain the problem to the duck.\n",
    "If you are lucky, you will realize that a small misunderstanding or mistake was the problem and fix it.\n",
    "\n",
    "![Picture of a rubber duck in front of a monitor](https://upload.wikimedia.org/wikipedia/commons/d/d5/Rubber_duck_assisting_with_debugging.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed22af-4016-40a5-91da-963e238349a3",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Possibilities \n",
    "After you are done with the exercise above take a look at the [matplotlib gallery](https://matplotlib.org/stable/gallery/index.html), [biopython](https://biopython.org/), [seaborn](https://seaborn.pydata.org/tutorial/introduction.html) and plan your future adventures with your rubber ducky.\n",
    "\n",
    "If you have any questions feel free to ask them now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
