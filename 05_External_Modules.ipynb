{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f24a2fd-7a01-4f13-be55-da271014f466",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# External modules\n",
    "\n",
    "Last unit we visualized Bobs data. Now we have to analyze them a little bit, afterwards we will talk about simulation, before we work with real data.\n",
    "\n",
    "So let us first take a look at the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab158d95-6ced-4ff2-977a-5c716eb0c505",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def process_csv(csv_file, dishes):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        cell_counter = 0\n",
    "        cell_area_counter = 0\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            cell_counter += 1\n",
    "            cell_area_counter += int(row[\" Cell Area\"])\n",
    "        if dish_number not in dishes.keys():\n",
    "            dishes[dish_number] = {}\n",
    "        dishes[dish_number][day] = {\n",
    "            \"cell_count\": cell_counter,\n",
    "            \"area\": cell_area_counter\n",
    "        } \n",
    "    return\n",
    "\n",
    "csv_files = list()\n",
    "data_folder = pathlib.Path(\"./data\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"dish_\" in csv_file.stem:\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "\n",
    "dishes = {}\n",
    "for csv_file in csv_files:\n",
    "    process_csv(csv_file, dishes)\n",
    "\n",
    "area = []\n",
    "count = []\n",
    "cells = {\"area\": area, \"count\": count}\n",
    "# We know that the dishes are numbered so we iterate over them<\n",
    "for dish_number in range(1, len(dishes) + 1, 1):\n",
    "    dish = dishes[dish_number]\n",
    "    dish_area = []\n",
    "    dish_count = []\n",
    "    # We know that the days in the dishes are numbered\n",
    "    for day_number in range(1, len(dish) + 1, 1):\n",
    "        value_pair = dish[day_number]\n",
    "        day_area = value_pair[\"area\"]\n",
    "        day_count = value_pair[\"cell_count\"]\n",
    "        dish_area.append(day_area)\n",
    "        dish_count.append(day_count)\n",
    "    area.append(dish_area)\n",
    "    count.append(dish_count)\n",
    "\n",
    "figure, axes = matplotlib.pyplot.subplots(2,1)\n",
    "days = [day for day in range(0, len(cells[\"count\"][0]), 1)]\n",
    "for dish in range(0, len(cells[\"count\"])):  \n",
    "    axes[0].plot(days, cells[\"count\"][dish], label=f\"Dish {dish}\")\n",
    "    axes[1].plot(days, cells[\"area\"][dish], label=f\"Dish {dish}\")\n",
    "figure.suptitle(\"Cell growth\")\n",
    "axes[0].set_title(\"Cell count\")\n",
    "axes[0].set_xlabel(\"Days\")\n",
    "axes[0].set_ylabel(\"Number of cells\")\n",
    "axes[1].set_title(\"Cell area\")\n",
    "axes[1].set_xlabel(\"Days\")\n",
    "axes[1].set_ylabel(\"Area covered by cells\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959cb46-58e0-4b0d-86d7-9df80316fea1",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Numerical differentiation\n",
    "\n",
    "After we have seen our two plots, it seems prudent to look at the growth rates now.\n",
    "As you may recall from your math studies the growth of the cells is the change in the number of cells or the first derivative of the numbers you see in front of you.\n",
    "Since we lack the underlying function, we have to solve this problem numerically,\n",
    "which means letting a computer handle it by a number-by-number basis.\n",
    "So how do we do this?\n",
    "\n",
    "During my high-school time the derivative was introduced via the [slope](https://en.wikipedia.org/wiki/Slope) of a function.\n",
    "We counted how much we went up or down on one axis comparted to the other,\n",
    "as shown in the following [illustration from Wikipedia](https://commons.wikimedia.org/wiki/File:Wiki_slope_in_2d.svg):\n",
    "\n",
    "![A slope illustrated with the interval steps on the x- and y-axis](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Wiki_slope_in_2d.svg/445px-Wiki_slope_in_2d.svg.png)\n",
    "\n",
    "Luckily, for us [numerical differentiation](https://en.wikipedia.org/wiki/Numerical_differentiation) did not progress much further, so we get the first derivative with the the original formula:\n",
    "\n",
    "$$\n",
    "m = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}}\n",
    "$$\n",
    "\n",
    "So we can get the forward slope, an approximation for the first order derivative by looking .\n",
    "\n",
    "We can get the forward slope, an approximation for the derivative by looking a certain distance ahead.\n",
    "In our case, the sample times indicate the length of this distance often called h.\n",
    "Our formula now takes the following form:\n",
    "\n",
    "$$\n",
    "f^{'}(x) = \\frac{f(x + h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "If you need a symmetric derivative, you may choose to look around the point of interest and use:\n",
    "\n",
    "$$\n",
    "f^{'}(x) = \\frac{f(x + h) - f(x - h)}{2 h}\n",
    "$$\n",
    "\n",
    "Should you need to calculate derivatives of mathematical functions you should look up [Taylor expansion](https://en.wikipedia.org/wiki/Taylor_series) and [finite difference coefficients](https://en.wikipedia.org/wiki/Finite_difference_coefficient).\n",
    "In this case you should also pay attention to the size of h.\n",
    "You can also reverse the process and numerically integrate, but there are special lectures for this topic that will warn you about the pitfalls in the different techniques.\n",
    "\n",
    "To round up this topic I would ask you to calculate the derivatives of the cell growth and plot them. Please use the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f90e4-4d4c-41cc-aea4-43f2226b1acd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# Feel free to copy from above what you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d85f26-7be0-49bb-9d3f-a93931bdf5ec",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def process_csv(csv_file, dishes):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        cell_counter = 0\n",
    "        cell_area_counter = 0\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            cell_counter += 1\n",
    "            cell_area_counter += int(row[\" Cell Area\"])\n",
    "        if dish_number not in dishes.keys():\n",
    "            dishes[dish_number] = {}\n",
    "        dishes[dish_number][day] = {\n",
    "            \"cell_count\": cell_counter,\n",
    "            \"area\": cell_area_counter\n",
    "        } \n",
    "    return\n",
    "\n",
    "csv_files = list()\n",
    "data_folder = pathlib.Path(\"./data\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"dish_\" in csv_file.stem:\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "\n",
    "dishes = {}\n",
    "for csv_file in csv_files:\n",
    "    process_csv(csv_file, dishes)\n",
    "\n",
    "area = []\n",
    "count = []\n",
    "cells = {\"area\": area, \"count\": count}\n",
    "# We know that the dishes are numbered so we iterate over them<\n",
    "for dish_number in range(1, len(dishes) + 1, 1):\n",
    "    dish = dishes[dish_number]\n",
    "    dish_area = []\n",
    "    dish_count = []\n",
    "    # We know that the days in the dishes are numbered\n",
    "    for day_number in range(1, len(dish) + 1, 1):\n",
    "        value_pair = dish[day_number]\n",
    "        day_area = value_pair[\"area\"]\n",
    "        day_count = value_pair[\"cell_count\"]\n",
    "        dish_area.append(day_area)\n",
    "        dish_count.append(day_count)\n",
    "    area.append(dish_area)\n",
    "    count.append(dish_count)\n",
    "\n",
    "def get_forward_derivative(series_x, series_y):\n",
    "    \"\"\" Gets the forward derivative\n",
    "\n",
    "    We chose the forward derivative, because it needs fewer values and still gives us some insight.\n",
    "    We can also calculate it for the first element in the series, which lacks a predecessor\n",
    "    \"\"\"\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(0, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index]\n",
    "        delta_y = series_y[index + 1] - series_y[index]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "    \n",
    "\n",
    "figure, axes = matplotlib.pyplot.subplots(2,1)\n",
    "days = [day for day in range(0, len(cells[\"count\"][0]), 1)]\n",
    "for dish in range(0, len(cells[\"count\"])):\n",
    "    # * unpacks the returned tuple into two values\n",
    "    axes[0].plot(*get_forward_derivative(days, cells[\"count\"][dish]), label=f\"Dish {dish}\")\n",
    "    axes[1].plot(*get_forward_derivative(days, cells[\"area\"][dish]), label=f\"Dish {dish}\")\n",
    "figure.suptitle(\"Cell growth\")\n",
    "axes[0].set_title(\"Cell count\")\n",
    "axes[0].set_xlabel(\"Days\")\n",
    "axes[0].set_ylabel(\"Change in the number of cells\")\n",
    "axes[1].set_title(\"Cell area\")\n",
    "axes[1].set_xlabel(\"Days\")\n",
    "axes[1].set_ylabel(\"Change in the area covered by cells\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f4088-2b6f-4c86-a11e-f80d597b60f2",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Histogram\n",
    "\n",
    "Now we want to find the correct way to describe the growth of our cells. \n",
    "While we could do this for every dish, it would be preferable to it for all of them together so we learn more about or cells in general.\n",
    "The first question we should answer is: “Are our cells comparable among each other?”\n",
    "In this case, we may wish to know how they compare in size to each other.\n",
    "We want to compare the cell sizes for each day and dish.\n",
    "Before we start throwing math at the problem, we should first look at one sample.\n",
    "The usual tool to visualize one-dimensional distributions is the histogram.\n",
    "It sorts numbers into bins or **lists**. \n",
    "So there is a **list** of 0 - 20 pixels of area an all the cells with this area go into this **list**.\n",
    "We then plot all the **lists** next to each other.\n",
    "Here is a code snippet to create a histogram the cell_area for dish 1 at day 5:\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def get_cell_areas(csv_file, cell_areas):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        areas = list()\n",
    "        for row in reader:\n",
    "            areas.append(int(row[\" Cell Area\"]))\n",
    "        if dish_number not in cell_areas.keys():\n",
    "            cell_areas[dish_number] = {}\n",
    "        cell_areas[dish_number][day] = areas \n",
    "    return\n",
    "\n",
    "csv_files = [pathlib.Path(\"./data/Day_5_dish_1.csv\")]\n",
    "\n",
    "cell_areas = dict()\n",
    "for csv_file in csv_files:\n",
    "    get_cell_areas(csv_file, cell_areas)\n",
    "\n",
    "matplotlib.pyplot.hist(cell_areas[1][5])\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "Please adapt this code to give you a histogram for all days and all dishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524447d-90e1-406b-ac35-fc2f814133dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561d079-395e-4721-9ced-23cf03c6c2fe",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def get_cell_areas(csv_file, cell_areas):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        areas = list()\n",
    "        for row in reader:\n",
    "            areas.append(int(row[\" Cell Area\"]))\n",
    "        if dish_number not in cell_areas.keys():\n",
    "            cell_areas[dish_number] = {}\n",
    "        cell_areas[dish_number][day] = areas \n",
    "    return\n",
    "\n",
    "csv_files = list()\n",
    "data_folder = pathlib.Path(\"./data\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"dish_\" in csv_file.stem:\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "all_cell_areas = list()\n",
    "for dish_number in cell_areas.keys():\n",
    "    dish = cell_areas[dish_number]\n",
    "    for day in dish.keys():\n",
    "        all_cell_areas += dish[day]\n",
    "\n",
    "cell_areas = dict()\n",
    "for csv_file in csv_files:\n",
    "    get_cell_areas(csv_file, cell_areas)\n",
    "\n",
    "matplotlib.pyplot.hist(all_cell_areas)\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d63a19-9497-42cd-a2f7-58e5739bc24d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As you see most of our cells are small over all days.\n",
    "This would now be the point where we play around with dishes and days and try to figure out how the distribution is influenced by day and dish.\n",
    "While it would be nice to play around on the data, we have some more Python ground to cover.\n",
    "Once you have your own data you will spend a lot of time with exploration, \n",
    "Which can be aided by more elegant packages like [pandas](https://pandas.pydata.org/docs/index.html). Pandas is a very useful package for data analysis and visualization and I suggest you spend a few afternoons to figure out if it can help you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e539c50-1eea-45e1-ae62-095d51907a07",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Mean, median and standard deviation\n",
    "\n",
    "Let us now return to our growth rate. \n",
    "We wish to obtain the bigger picture or figure out how the growth performs in general.\n",
    "So far, we used our brains to do this visually, but we do not have numbers.\n",
    "How do we get a growth number from our five dishes?\n",
    "\n",
    "The first step would probably be to combine all the dishes into one dish. \n",
    "In other words we need an abstract measure for the growth rate of all dishes.\n",
    "We have a few mathematical tools to obtain such a measure.\n",
    "\n",
    "The simplest one is the average or the mean.\n",
    "The sum of all elements divided by the number of elements.\n",
    "Nicely represented by ```numpy.mean```.\n",
    "\n",
    "The disadvantage is its sensitivity to outliers. \n",
    "If the average PhD takes 51 months computer scientists take 60 months veterinarians may take less time[DFG](https://www.dfg.de/de/service/presse/pressemitteilungen/2021/pressemitteilung-nr-09).\n",
    "It becomes more fun if you are doing your PhD in philosophy where the average is around 55 months.\n",
    "You may already plan your life accordingly just to realize that the person sitting on the desk across you is already working on their PhD for seven years and far from completion[DFG](https://www.dfg.de/de/service/presse/pressemitteilungen/2021/pressemitteilung-nr-09).\n",
    "\n",
    "This issues means we need better ways to describe our data.\n",
    "The next one we can use is the middle value or the median,\n",
    "which we can obtain via ```numpy.median```.\n",
    "\n",
    "The last measure is the [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation), measuring how strongly values deviate from a mean.\n",
    "It only works if we use normally distributed values, similar in shape to the following graph from [Wikipedia](https://commons.wikimedia.org/wiki/File:Standard_deviation_diagram.svg):\n",
    "\n",
    "![A bell shaped normal distribution](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/640px-Standard_deviation_diagram.svg.png)\n",
    "\n",
    "This is often the case because our observed variables are independent random variables,\n",
    "Which form a normal distribution if sampled often enough according to the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem).\n",
    "If your data in the future are distributed can be tested with a few statistic tests.\n",
    "Those tests are not simple to apply or interpret so I advise you to either attend a statistics lecture or cooperate with someone that did.\n",
    "\n",
    "Now back to our problem.\n",
    "Since the standard deviation, which we can calculate using ```numpy.std``` can serve as an error-measurement we wish to include it.\n",
    "\n",
    "Please plot the growth rates median and mean. The  latter one should be plotted with errorbars using the standard deviation. Please enter your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434bf11-2749-47b5-81d2-f1214780ddd1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6935d-fd0b-499a-9fe1-ec8a9bb95356",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import numpy\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def process_csv(csv_file, dishes):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        cell_counter = 0\n",
    "        cell_area_counter = 0\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            cell_counter += 1\n",
    "            cell_area_counter += int(row[\" Cell Area\"])\n",
    "        if dish_number not in dishes.keys():\n",
    "            dishes[dish_number] = {}\n",
    "        dishes[dish_number][day] = {\n",
    "            \"cell_count\": cell_counter,\n",
    "            \"area\": cell_area_counter\n",
    "        } \n",
    "    return\n",
    "\n",
    "csv_files = list()\n",
    "data_folder = pathlib.Path(\"./data\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"dish_\" in csv_file.stem:\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "\n",
    "dishes = {}\n",
    "for csv_file in csv_files:\n",
    "    process_csv(csv_file, dishes)\n",
    "\n",
    "area = []\n",
    "count = []\n",
    "cells = {\"area\": area, \"count\": count}\n",
    "# We know that the dishes are numbered so we iterate over them<\n",
    "for dish_number in range(1, len(dishes) + 1, 1):\n",
    "    dish = dishes[dish_number]\n",
    "    dish_area = []\n",
    "    dish_count = []\n",
    "    # We know that the days in the dishes are numbered\n",
    "    for day_number in range(1, len(dish) + 1, 1):\n",
    "        value_pair = dish[day_number]\n",
    "        day_area = value_pair[\"area\"]\n",
    "        day_count = value_pair[\"cell_count\"]\n",
    "        dish_area.append(day_area)\n",
    "        dish_count.append(day_count)\n",
    "    area.append(dish_area)\n",
    "    count.append(dish_count)\n",
    "\n",
    "def get_forward_derivative(series_x, series_y):\n",
    "    \"\"\" Gets the forward derivative\n",
    "\n",
    "    We chose the forward derivative, because it needs fewer values and still gives us some insight.\n",
    "    We can also calculate it for the first element in the series, which lacks a predecessor\n",
    "    \"\"\"\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(0, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index]\n",
    "        delta_y = series_y[index + 1] - series_y[index]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "    \n",
    "days = [day for day in range(0, len(cells[\"count\"][0]))]\n",
    "days_derived = days[0:-1]\n",
    "growth_number_of_cells = [list() for day in days]\n",
    "growth_area = [list() for day in days]\n",
    "\n",
    "for dish in range(0, len(cells[\"count\"])):\n",
    "    current_growth_number_of_cells = get_forward_derivative(days, cells[\"count\"][dish])[1]\n",
    "    current_growth_area = get_forward_derivative(days, cells[\"area\"][dish])[1]\n",
    "    for day in range(0, len(days_derived)):\n",
    "        growth_number_of_cells[day].append(current_growth_number_of_cells[day])\n",
    "        growth_area[day].append(current_growth_area[day])\n",
    "        \n",
    "growth_number_of_cells_median = list()\n",
    "growth_number_of_cells_mean = list()\n",
    "growth_number_of_cells_std = list()\n",
    "growth_area_median = list()\n",
    "growth_area_mean = list()\n",
    "growth_area_std = list()\n",
    "for day in range(0, len(days_derived)):\n",
    "    current_values_count = growth_number_of_cells[day]\n",
    "    growth_number_of_cells_median.append(numpy.median(current_values_count))\n",
    "    growth_number_of_cells_mean.append(numpy.mean(current_values_count))\n",
    "    growth_number_of_cells_std.append(numpy.std(current_values_count))\n",
    "    current_values_area = growth_area[day]\n",
    "    growth_area_median.append(numpy.median(current_values_area))\n",
    "    growth_area_mean.append(numpy.mean(current_values_area))\n",
    "    growth_area_std.append(numpy.std(current_values_area))\n",
    "\n",
    "figure, axes = matplotlib.pyplot.subplots(2,1)\n",
    "figure.suptitle(\"Cell growth\")\n",
    "# Formatting the plots to use circles \"o\" and crosses \"x\".\n",
    "# For further information consult: https://matplotlib.org/stable/api/markers_api.html#module-matplotlib.markers\n",
    "axes[0].errorbar(days_derived, growth_number_of_cells_mean, yerr=growth_number_of_cells_std, fmt=\"o\", label = \"mean\")\n",
    "axes[0].plot(days_derived, growth_number_of_cells_median, \"x\", label = \"median\")\n",
    "axes[0].set_title(\"Cell count\")\n",
    "axes[0].set_xlabel(\"Days\")\n",
    "axes[0].set_ylabel(\"Change in the number of cells\")\n",
    "axes[1].errorbar(days_derived, growth_area_mean, yerr=growth_area_std, fmt=\"o\", label = \"mean\")\n",
    "axes[1].plot(days_derived, growth_area_median, \"x\", label = \"median\")\n",
    "axes[1].set_title(\"Cell area\")\n",
    "axes[1].set_xlabel(\"Days\")\n",
    "axes[1].set_ylabel(\"Change in the area covered by cells\")\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addeedb3-743e-470b-ac34-26938522a650",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fitting\n",
    "\n",
    "Now we have reduced our problem to a small set of simpler numbers, but what we really want is a growth rate.\n",
    "To obtain this growth rate we need to fit a mathematical model.\n",
    "This model is sourced either from existing literature or developed based on observations or domain specific arguments.\n",
    "In our case we will try to fit an exponential function, assuming our cells grow exponentially and a [polynomial](https://en.wikipedia.org/wiki/Polynomial) to see the difference.\n",
    "\n",
    "I suggest you begin with the polynomial and the graduate to the exponential function.\n",
    "For the fitting I would suggest you use ```scipy.optimive.curve_fit```.\n",
    "Please fit an exponential function and a polynomial of third order to the cell-count.\n",
    "Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44ce24-4213-4364-a41d-6c66ba9e4fda",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d543022-3b4c-41d3-a619-169fc2d30b26",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested solution </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import numpy\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "import scipy.optimize\n",
    "\n",
    "def process_csv(csv_file, dishes):\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        _, day, _ , dish_number = str(csv_file.stem).split(\"_\")\n",
    "        day = int(day)\n",
    "        dish_number = int(dish_number)\n",
    "        cell_counter = 0\n",
    "        cell_area_counter = 0\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            cell_counter += 1\n",
    "            cell_area_counter += int(row[\" Cell Area\"])\n",
    "        if dish_number not in dishes.keys():\n",
    "            dishes[dish_number] = {}\n",
    "        dishes[dish_number][day] = {\n",
    "            \"cell_count\": cell_counter,\n",
    "            \"area\": cell_area_counter\n",
    "        } \n",
    "    return\n",
    "\n",
    "csv_files = list()\n",
    "data_folder = pathlib.Path(\"./data\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"dish_\" in csv_file.stem:\n",
    "        csv_files.append(csv_file)\n",
    "\n",
    "\n",
    "dishes = {}\n",
    "for csv_file in csv_files:\n",
    "    process_csv(csv_file, dishes)\n",
    "\n",
    "area = []\n",
    "count = []\n",
    "cells = {\"area\": area, \"count\": count}\n",
    "# We know that the dishes are numbered so we iterate over them<\n",
    "for dish_number in range(1, len(dishes) + 1, 1):\n",
    "    dish = dishes[dish_number]\n",
    "    dish_area = []\n",
    "    dish_count = []\n",
    "    # We know that the days in the dishes are numbered\n",
    "    for day_number in range(1, len(dish) + 1, 1):\n",
    "        value_pair = dish[day_number]\n",
    "        day_area = value_pair[\"area\"]\n",
    "        day_count = value_pair[\"cell_count\"]\n",
    "        dish_area.append(day_area)\n",
    "        dish_count.append(day_count)\n",
    "    area.append(dish_area)\n",
    "    count.append(dish_count)\n",
    "\n",
    "def get_forward_derivative(series_x, series_y):\n",
    "    \"\"\" Gets the forward derivative\n",
    "\n",
    "    We chose the forward derivative, because it needs fewer values and still gives us some insight.\n",
    "    We can also calculate it for the first element in the series, which lacks a predecessor\n",
    "    \"\"\"\n",
    "    if len(series_x) != len(series_y):\n",
    "        raise ValueError(f\"{series_x} did not have the same number of elements as {series_y}\")\n",
    "    return_x = list()\n",
    "    return_y = list()\n",
    "    # Remeber that the last element has no sucessor and we can therefore not get a derivative for it\n",
    "    for index in range(0, len(series_x) - 1, 1):\n",
    "        delta_x = series_x[index + 1] - series_x[index]\n",
    "        delta_y = series_y[index + 1] - series_y[index]\n",
    "        slope = delta_y / delta_x\n",
    "        return_x.append(series_x[index])\n",
    "        return_y.append(slope)\n",
    "    return return_x, return_y\n",
    "    \n",
    "\n",
    "days = [day for day in range(0, len(cells[\"count\"][0]))]\n",
    "days_derived = days[0:-1]\n",
    "growth_number_of_cells = [list() for day in days]\n",
    "growth_area = [list() for day in days]\n",
    "\n",
    "for dish in range(0, len(cells[\"count\"])):\n",
    "    current_growth_number_of_cells = get_forward_derivative(days, cells[\"count\"][dish])[1]\n",
    "    current_growth_area = get_forward_derivative(days, cells[\"area\"][dish])[1]\n",
    "    for day in range(0, len(days_derived)):\n",
    "        growth_number_of_cells[day].append(current_growth_number_of_cells[day])\n",
    "        growth_area[day].append(current_growth_area[day])\n",
    "        \n",
    "growth_number_of_cells_mean = list()\n",
    "growth_number_of_cells_std = list()\n",
    "growth_area_mean = list()\n",
    "growth_area_std = list()\n",
    "for day in range(0, len(days_derived)):\n",
    "    current_values_count = growth_number_of_cells[day]\n",
    "    growth_number_of_cells_mean.append(numpy.mean(current_values_count))\n",
    "    growth_number_of_cells_std.append(numpy.std(current_values_count))\n",
    "    current_values_area = growth_area[day]\n",
    "    growth_area_mean.append(numpy.mean(current_values_area))\n",
    "    growth_area_std.append(numpy.std(current_values_area))\n",
    "\n",
    "def exponential(x, a, b, c):\n",
    "    return a*numpy.exp(b*x) + c\n",
    "\n",
    "def third_order_polynomial(x, a, b, c, d):\n",
    "    return a + b * x + c * (x ** 2) + d *  (x ** 3)\n",
    "\n",
    "exponential_optimized_parameters, exponential_parameters_covariance = scipy.optimize.curve_fit(exponential, days_derived, growth_number_of_cells_mean)\n",
    "# Consult https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html Retruns for the covariance\n",
    "exponential_std_parameters = numpy.sqrt(numpy.std(exponential_count_parameters_covariance))\n",
    "print(f\"Exponetial: {exponential_optimized_parameters[0]:f} * e ^ (x * {exponential_optimized_parameters[1]:f}) + {exponential_optimized_parameters[2]:f} std: {exponential_std_parameters:f}\")\n",
    "polynomial_optimized_parameters, polynomial_parameters_covariance = scipy.optimize.curve_fit(third_order_polynomial, days_derived, growth_number_of_cells_mean)\n",
    "# Consult https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html Retruns for the covariance\n",
    "polynomial_std_parameters = numpy.sqrt(numpy.std(polynomial_parameters_covariance))\n",
    "print(f\"Polynomial: {polynomial_optimized_parameters[0]:f} + {polynomial_optimized_parameters[1]:f} * x + {polynomial_optimized_parameters[2]:f} * (x^2) + {polynomial_optimized_parameters[3]:f} * (x^3) std: {polynomial_std_parameters:f}\")\n",
    "\n",
    "matplotlib.pyplot.errorbar(days_derived, growth_number_of_cells_mean, yerr=growth_number_of_cells_std, fmt=\"o\", label = \"mean\")\n",
    "matplotlib.pyplot.plot(days_derived, exponential(numpy.array(days_derived), *exponential_optimized_parameters), \"-\", label = \"exponential-fit\")\n",
    "matplotlib.pyplot.plot(days_derived, third_order_polynomial(numpy.array(days_derived), *polynomial_optimized_parameters), \"-\", label = \"polynomial-fit\")\n",
    "matplotlib.pyplot.title(\"Cell count\")\n",
    "matplotlib.pyplot.xlabel(\"Days\")\n",
    "matplotlib.pyplot.ylabel(\"Change in the number of cells\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2ad3a-5a62-4407-978c-bd19e0bdcd09",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simulation\n",
    "\n",
    "As you know, Alice and Bob are not real and neither are their data, so how did I generate the csv-files.  The answer to this is simulation. Especially in Physics simulations are often used tool to answer questions that cannot be answered with simple experiments. If we want to know how galaxies form we can neither make one in our own backyard nor can we observe it in our lifetimes, so we build a mathematical model in a computer and investigate it.\n",
    "\n",
    "In biology, computer simulations are more difficult to perform, because we lack a sufficiently advanced mathematical understanding of the problems we investigate. Expressed in a simpler way “it is easier to calculate how two galaxies collide, than how two cell interacts with each other. You can see this on the way I simulated our cells.\n",
    "\n",
    "I first created a big empty dish. Then I placed a cell in it and let its nucleus grow while growing a cell body around it. Whenever the nucleus split by accident, I considered this a normal cell division. If a cell lost most of its body or was too small, I considered it dead. If you find this simplification revolting, you have already understood why biology is not easy to simulate. There are a lot more nuances and rules to consider than in Physics.\n",
    "\n",
    "I mention that simulations exist, because I believe that during your career you will may encounter questions that can be answered by writing a short program and running it instead of using a plant or animal and that the use of simulation will slowly proliferate within biology. For the latter case always remember that a simulation is a simplified mathematical model and therefore flawed, so if you use it always ask which corners were cut and how this will influence your research.\n",
    "\n",
    "The code I used to create the csv-files can be found in ```cell_simulation.py```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eab2e-0c30-4b86-89b9-384d606375f0",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Rubber duck debugging\n",
    "\n",
    "During this course, you were able to work with your partners.\n",
    "Working on the course together, you were able to engage naturally in [pair programming](https://en.wikipedia.org/wiki/Pair_programming) and [code review](https://en.wikipedia.org/wiki/Code_review). \n",
    "These methods greatly improve your understanding of the problem and thereby your code.\n",
    "It is unfortunately difficult to communicate the advantages of efficient work to superior and colleagues.\n",
    "The preferred standard is to let two people on two desks solve in eight days, what two people on one desk could have solved in four.\n",
    "Therefore, you will find yourself most probably working on your problems alone.\n",
    "Luckily, not some of the benefits of working with a partner can be gained without one.\n",
    "\n",
    "A good example of this is [rubber duck debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging).\n",
    "It is especially useful for novice programmers as yourself or problems with many steps.\n",
    "The general idea is that explaining something requires you to think more deeply about it,\n",
    "therefore you can improve your understanding and by explaining.\n",
    "So, you need to explain your code to figure out why it does not do what it is supposed to.\n",
    "While a live human can contribute his or her own insights, a rubber duck is sufficient to gain your own.\n",
    "So if you struggle with a problem take a rubber duck and explain the problem to the duck.\n",
    "If you are lucky, you will realize that a small misunderstanding or mistake was the problem and fix it.\n",
    "\n",
    "![Picture of a rubber duck in front of a monitor](https://upload.wikimedia.org/wikipedia/commons/d/d5/Rubber_duck_assisting_with_debugging.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21ad30-a3a8-4d3f-814c-1dda8a6770fb",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Real data\n",
    "\n",
    "Now it is time to apply what you have learned to real data.\n",
    "Let me introduce the problem similar to Bobs question:\n",
    "\n",
    "Our group focuses how oxytocin, a neurohormone synthesized in the hypothalamus, influences maternal care.\n",
    "A major feature of mammalian maternal care is milk supply through the mammary gland.\n",
    "You may have already heard that oxytocin is secreted into the blood stream in the pituitary gland following suckling of the offspring.\n",
    "It elicits milk ejections by evoking contractions of smooth muscle cells in the mammary ducts.\n",
    "\n",
    "Interestingly, oxytocin is not continuously secreted during suckling but released in bursts.\n",
    "This burst-like secretion is caused by bursts of oxytocin neural activity.\n",
    "We try to understand how this activity is generated, by investigating the behavior of rats and activity in their brains.\n",
    "\n",
    "The example we picked for you is the analysis of such neural activity with behavioral data.\n",
    "You will work with our experimental data.\n",
    "This data consists of extracellular spike (neuroscientists call action potential \"spikes\") recordings in which many cells have been recorded simultaneously, as well as pre-analyzed video-based behavioral data.\n",
    "We analyzed the movement of the dam, because the animal stops moving before milk ejection. \n",
    "\n",
    "Only one of the cells recorded is a potential oxytocin neuron.\n",
    "The final goal of the course will be to find this oxytocin neuron by identifying the characteristic firing pattern shown in the following image.\n",
    "\n",
    "![Sketch of the experiment and resulting plot](img/experiment.jpg)\n",
    "\n",
    "A. Recording setup with an electrode that has many contacts along one [single shank](https://en.wikipedia.org/wiki/Neuropixels).\n",
    "B. Top: Maternal behavior (immobility vs. mobility).\n",
    "Bottom: Neural activity. Note that we see the spikes per second (Hz).\n",
    "We also see that there are seven distinct bursts measuring around 100 spikes per second.\n",
    "Also, note that the burst pattern seen here has been described to coincide with immobility.\n",
    "The combined investigation of both neural activity and behavior thus provides converging evidence that the recorded neuron is an oxytocin neuron.\n",
    "\n",
    "![The action potential of a Oxytocin cell showing a burst with multiple spikes](img/OTburst.png)\n",
    "\n",
    "An example of an oxytocin burst consisting of multiple spikes. You can see a large number of spikes in the center of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2547d-2b4d-481a-bcbd-6f7e333b2371",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In ```data_neuron``` you will find the recording of individual units and the mothers behavior.\n",
    "Units are signals that belong together. \n",
    "One of the signals is the oxytocin signal, we wish to find it by checking if most bursts occur within the immobility.\n",
    "To make the task a little bit easier we have simplified the immobility to two large instead of many small events.\n",
    "We also shortened the original data to 3.0 seconds.\n",
    "\n",
    "To detect a burst you will have to check when the number of spikes per second goes over a threshold.\n",
    "This means you need the number of spikes per second.\n",
    "So, you need to estimate the temporal density of the spikes, which can be achieved with [kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation).\n",
    "The simplest possible kernel simply counts if something is in a bin.\n",
    "So we create a bin for every seconds and count the spikes within.\n",
    "\n",
    "Good luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb12d4-f8c6-49c0-97d3-c9a7ca82efd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3ed5d-6859-497d-9a9e-7aeb2337acd8",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show approach hint </summary>\n",
    "\n",
    "First, we look at the data and it becomes clear that we have to write two-csv-readers.\n",
    "If we investigate the units, we also see that there are multiple units stored in the same file, so we have to sort them.\n",
    "\n",
    "Next, we have to ask ourselves what we are searching.\n",
    "We want the number of spikes within one second, which we can get by binning.\n",
    "This suggests that we either use ```matplotlib.pyplot.hist``` or ```numpy.histogram```,\n",
    "By setting the bin sizes to 1 we can get the frequency in Hz.\n",
    "\n",
    "Lastly, we have to mark the immobility areas in the plot.\n",
    "A online search may lead us to [stack overflow](https://stackoverflow.com/questions/61282135/set-the-background-color-on-a-plot-in-specific-alternate-intervals-of-dates-or-o) and indirectly to [axvspan](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axvspan.html).\n",
    "\n",
    "These are the ingridients for our algorithm.\n",
    "\n",
    "So our plan is:\n",
    "1. Read in the csv-files\n",
    "2. Extract the immoblility times\n",
    "3. Extract the spikes for every unit\n",
    "4. Plot the immobility times as a background or line\n",
    "5. Plot the spike times into a histogram with small binning (1 second)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae11ed84-520b-4f62-baba-d9a923121ee4",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested csv search </summary>\n",
    "\n",
    "```Python\n",
    "import pathlib\n",
    "\n",
    "unit_file = None\n",
    "immobility_file = None\n",
    "data_folder = pathlib.Path(\"./data_neuron\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"units\" in csv_file.stem:\n",
    "        unit_file = csv_file\n",
    "    elif \"immobility\" in csv_file.stem:\n",
    "        immobility_file = csv_file\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7514d-f2a0-484b-a945-add8786ea251",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested unit read in function </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "\n",
    "def process_unit_csv(csv_file):\n",
    "    \"\"\"Read in the spike times of a neuronal unit\n",
    "\n",
    "    We expect that the file has a header and a column named \"spikeTimes\" containing time-stamps in seconds\n",
    "    and a column \"unitID\" used to identify the units in the file.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file -- the path to the file\n",
    "    \"\"\"\n",
    "    units = dict()\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            unit_id = row[\"unitID\"]\n",
    "            if unit_id not in units.keys():\n",
    "                units[unit_id] = list()\n",
    "            units[unit_id].append(float(row[\"spikeTimes\"]))\n",
    "    return units\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a078fb-341f-406c-a9a1-cb9ff8a42ea0",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested immobility read in function </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "\n",
    "def process_immobility_csv(csv_file):\n",
    "    \"\"\"Read in the simmobility of the mother\n",
    "\n",
    "    We expect that the file has a header and a column named \"begin in seconds\" containing begin of the immobility in seconds\n",
    "    and a column \"end in seconds\" containing end of the immobility in seconds.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file -- the path to the file\n",
    "    \"\"\"\n",
    "    immobility = list()\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            begin = int(row[\"begin in seconds\"])\n",
    "            end = int(row[\"end in seconds\"])\n",
    "            immobility.append((begin, end))\n",
    "    return immobility\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c5b27-11ec-4e5c-899b-2fee2f89d72c",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested plotting </summary>\n",
    "\n",
    "```Python\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "\n",
    "for unit in units.keys():\n",
    "    max_duration = 3400\n",
    "    # Not that the lower bin size impliitly dictates the lowest detected frequency\n",
    "    # This could be solved by using a smoothing kernel, but here even some signal is good enough\n",
    "    # 0.1 was the size used in the plot, giving us the minimal value of 10 Hz\n",
    "    bin_size = 0.1\n",
    "    numpy_bins = numpy.arange(0, max_duration, 0.1)\n",
    "    units_binned, bin_edges = numpy.histogram(units[unit], bins = numpy_bins)\n",
    "    units_binned = units_binned / bin_size\n",
    "\n",
    "    matplotlib.pyplot.title(f\"Unit {unit}\")   \n",
    "    # plot invervals to compare\n",
    "    for begin, end in immobility:\n",
    "         matplotlib.pyplot.axvspan(begin, end, facecolor='black', alpha=0.2)\n",
    "    matplotlib.pyplot.stairs(units_binned, bin_edges)\n",
    "    matplotlib.pyplot.xlabel(\"Time in seconds\")\n",
    "    matplotlib.pyplot.ylabel(\"Frequency in Hz\")\n",
    "    # An y limit makes the plots more comparable\n",
    "    matplotlib.pyplot.ylim((0, 130))\n",
    "    matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5ccef-5f57-4612-945c-9ca767b41cc4",
   "metadata": {
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "<summary> Show suggested complete solution </summary>\n",
    "\n",
    "```Python\n",
    "import csv\n",
    "import numpy\n",
    "import pathlib\n",
    "import matplotlib.pyplot\n",
    "\n",
    "def process_unit_csv(csv_file):\n",
    "    \"\"\"Read in the spike times of a neuronal unit\n",
    "\n",
    "    We expect that the file has a header and a column named \"spikeTimes\" containing time-stamps in seconds\n",
    "    and a column \"unitID\" used to identify the units in the file.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file -- the path to the file\n",
    "    \"\"\"\n",
    "    units = dict()\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            unit_id = row[\"unitID\"]\n",
    "            if unit_id not in units.keys():\n",
    "                units[unit_id] = list()\n",
    "            units[unit_id].append(float(row[\"spikeTimes\"]))\n",
    "    return units\n",
    "\n",
    "def process_immobility_csv(csv_file):\n",
    "    \"\"\"Read in the simmobility of the mother\n",
    "\n",
    "    We expect that the file has a header and a column named \"begin in seconds\" containing begin of the immobility in seconds\n",
    "    and a column \"end in seconds\" containing end of the immobility in seconds.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_file -- the path to the file\n",
    "    \"\"\"\n",
    "    immobility = list()\n",
    "    with open(csv_file, \"r\") as csv_file_handle:\n",
    "        reader = csv.DictReader(csv_file_handle)\n",
    "        for row in reader:\n",
    "            begin = int(row[\"begin in seconds\"])\n",
    "            end = int(row[\"end in seconds\"])\n",
    "            immobility.append((begin, end))\n",
    "    return immobility\n",
    "\n",
    "unit_file = None\n",
    "immobility_file = None\n",
    "data_folder = pathlib.Path(\"./data_neuron\")\n",
    "for csv_file in data_folder.iterdir():\n",
    "    if \"units\" in csv_file.stem:\n",
    "        unit_file = csv_file\n",
    "    elif \"immobility\" in csv_file.stem:\n",
    "        immobility_file = csv_file\n",
    "\n",
    "units = process_unit_csv(unit_file)\n",
    "immobility = process_immobility_csv(immobility_file)\n",
    "\n",
    "for unit in units.keys():\n",
    "    max_duration = 3400\n",
    "    # Not that the lower bin size impliitly dictates the lowest detected frequency\n",
    "    # This could be solved by using a smoothing kernel, but here even some signal is good enough\n",
    "    # 0.1 was the size used in the plot, giving us the minimal value of 10 Hz\n",
    "    bin_size = 0.1\n",
    "    numpy_bins = numpy.arange(0, max_duration, 0.1)\n",
    "    units_binned, bin_edges = numpy.histogram(units[unit], bins = numpy_bins)\n",
    "    units_binned = units_binned / bin_size\n",
    "\n",
    "    matplotlib.pyplot.title(f\"Unit {unit}\")   \n",
    "    # plot invervals to compare\n",
    "    for begin, end in immobility:\n",
    "         matplotlib.pyplot.axvspan(begin, end, facecolor='black', alpha=0.2)\n",
    "    matplotlib.pyplot.stairs(units_binned, bin_edges)\n",
    "    matplotlib.pyplot.xlabel(\"Time in seconds\")\n",
    "    matplotlib.pyplot.ylabel(\"Frequency in Hz\")\n",
    "    # An y limit makes the plots more comparable\n",
    "    matplotlib.pyplot.ylim((0, 130))\n",
    "    matplotlib.pyplot.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed22af-4016-40a5-91da-963e238349a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Possibilities \n",
    "After you are done with the exercise above take a look at the [matplotlib gallery](https://matplotlib.org/stable/gallery/index.html), [biopython](https://biopython.org/), [seaborn](https://seaborn.pydata.org/tutorial/introduction.html) and plan your future adventures with your rubber ducky.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
